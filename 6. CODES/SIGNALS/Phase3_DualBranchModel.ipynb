{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d32243f",
   "metadata": {},
   "source": [
    "# Phase 3: Dual-Branch Meta-Labeling Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements a dual-branch neural network architecture for meta-labeling:\n",
    "- **Branch 1 (Classification)**: Predicts entry signal confidence (should we take this trade?)\n",
    "- **Branch 2 (Regression)**: Predicts outcome heatmap (signed_heatmap_entry: [-1, +1])\n",
    "\n",
    "## Architecture\n",
    "Inspired by swim_code dual-branch CNN-LSTM:\n",
    "- Shared CNN layers for feature extraction\n",
    "- Branch 1: CNN → Flatten → Dense → Sigmoid (binary classification)\n",
    "- Branch 2: CNN → LSTM → Dense → Tanh (regression to [-1, +1])\n",
    "\n",
    "## Input/Output\n",
    "- Input: Sequences (60, n_features) from Phase 2\n",
    "- Output 1: Entry confidence [0, 1]\n",
    "- Output 2: Outcome prediction [-1, +1]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494e94e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle \n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc2d61",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('../DATA')\n",
    "MODEL_DIR = Path('../MODELS')\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Model hyperparameters\n",
    "CONFIG = {\n",
    "    # Architecture\n",
    "    'shared_conv_filters': [32, 64, 128],\n",
    "    'shared_kernel_sizes': [3, 3, 3],\n",
    "    'shared_strides': [1, 1, 1],\n",
    "    'shared_pool_sizes': [2, 2, 2],\n",
    "    \n",
    "    # Branch 1 (Classification)\n",
    "    'class_dense_units': [64, 32],\n",
    "    'class_dropout': 0.3,\n",
    "    'class_l2': 0.001,\n",
    "    \n",
    "    # Branch 2 (Regression)\n",
    "    'reg_lstm_units': 64,\n",
    "    'reg_lstm_dropout': 0.2,\n",
    "    'reg_lstm_recurrent_dropout': 0.2,\n",
    "    'reg_dense_units': [32],\n",
    "    'reg_dropout': 0.2,\n",
    "    'reg_l2': 0.001,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 15,\n",
    "    \n",
    "    # Loss weights (balance between classification and regression)\n",
    "    'classification_weight': 0.4,\n",
    "    'regression_weight': 0.6,\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada3a70",
   "metadata": {},
   "source": [
    "## 3. Load Processed Data from Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1919c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "with open(DATA_DIR / 'data_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"Dataset metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Load sequences and targets\n",
    "print(\"\\nLoading data files...\")\n",
    "X_train = np.load(DATA_DIR / 'X_train_scaled.npy')\n",
    "y_train = np.load(DATA_DIR / 'y_train.npy')\n",
    "X_val = np.load(DATA_DIR / 'X_val_scaled.npy')\n",
    "y_val = np.load(DATA_DIR / 'y_val.npy')\n",
    "X_test = np.load(DATA_DIR / 'X_test_scaled.npy')\n",
    "y_test = np.load(DATA_DIR / 'y_test.npy')\n",
    "\n",
    "print(f\"\\nData shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Input shape for model\n",
    "input_shape = X_train.shape[1:]  # (60, n_features)\n",
    "print(f\"\\nInput shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3aaf2d",
   "metadata": {},
   "source": [
    "## 4. Prepare Dual Targets\n",
    "\n",
    "For meta-labeling, we need two targets:\n",
    "1. **Classification**: Binary label (good bet vs bad bet)\n",
    "   - Good bet: |signed_heatmap_entry| > threshold (strong signal)\n",
    "   - Bad bet: |signed_heatmap_entry| ≤ threshold (weak signal)\n",
    "2. **Regression**: Continuous signed_heatmap_entry [-1, +1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification threshold: consider trades with |heatmap| > 0.3 as \"good bets\"\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "\n",
    "# Create classification labels (0 = bad bet, 1 = good bet)\n",
    "y_train_class = (np.abs(y_train) > CONFIDENCE_THRESHOLD).astype(np.float32)\n",
    "y_val_class = (np.abs(y_val) > CONFIDENCE_THRESHOLD).astype(np.float32)\n",
    "y_test_class = (np.abs(y_test) > CONFIDENCE_THRESHOLD).astype(np.float32)\n",
    "\n",
    "# Regression targets (keep as-is)\n",
    "y_train_reg = y_train.astype(np.float32)\n",
    "y_val_reg = y_val.astype(np.float32)\n",
    "y_test_reg = y_test.astype(np.float32)\n",
    "\n",
    "print(f\"Classification target distribution:\")\n",
    "print(f\"  Train - Good bets: {y_train_class.mean():.2%}, Bad bets: {(1-y_train_class.mean()):.2%}\")\n",
    "print(f\"  Val   - Good bets: {y_val_class.mean():.2%}, Bad bets: {(1-y_val_class.mean()):.2%}\")\n",
    "print(f\"  Test  - Good bets: {y_test_class.mean():.2%}, Bad bets: {(1-y_test_class.mean()):.2%}\")\n",
    "\n",
    "print(f\"\\nRegression target statistics:\")\n",
    "print(f\"  Train - Mean: {y_train_reg.mean():.4f}, Std: {y_train_reg.std():.4f}\")\n",
    "print(f\"  Val   - Mean: {y_val_reg.mean():.4f}, Std: {y_val_reg.std():.4f}\")\n",
    "print(f\"  Test  - Mean: {y_test_reg.mean():.4f}, Std: {y_test_reg.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183f826",
   "metadata": {},
   "source": [
    "## 5. Build Dual-Branch Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dual_branch_model(input_shape, config):\n",
    "    \"\"\"\n",
    "    Build dual-branch model for meta-labeling:\n",
    "    - Branch 1: Classification (entry confidence)\n",
    "    - Branch 2: Regression (outcome prediction)\n",
    "    \n",
    "    Architecture inspired by swim_code dual-branch CNN-LSTM.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # Reshape for Conv2D: (batch, timesteps, features) → (batch, timesteps, features, 1)\n",
    "    x = layers.Reshape((input_shape[0], input_shape[1], 1), name='reshape_input')(inputs)\n",
    "    \n",
    "    # ===== Shared CNN Layers for Feature Extraction =====\n",
    "    for i, (filters, kernel_size, stride, pool_size) in enumerate(zip(\n",
    "        config['shared_conv_filters'],\n",
    "        config['shared_kernel_sizes'],\n",
    "        config['shared_strides'],\n",
    "        config['shared_pool_sizes']\n",
    "    )):\n",
    "        x = layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            strides=(stride, 1),\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name=f'shared_conv_{i}'\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization(name=f'shared_bn_{i}')(x)\n",
    "        x = layers.Activation('relu', name=f'shared_activation_{i}')(x)\n",
    "        if pool_size > 1:\n",
    "            x = layers.MaxPooling2D(pool_size=(pool_size, 1), name=f'shared_pool_{i}')(x)\n",
    "    \n",
    "    shared_features = x\n",
    "    \n",
    "    # ===== Branch 1: Classification (Entry Confidence) =====\n",
    "    # Flatten shared features for classification\n",
    "    class_branch = layers.Flatten(name='class_flatten')(shared_features)\n",
    "    \n",
    "    for i, units in enumerate(config['class_dense_units']):\n",
    "        class_branch = layers.Dense(\n",
    "            units=units,\n",
    "            kernel_regularizer=l2(config['class_l2']),\n",
    "            kernel_initializer='he_normal',\n",
    "            name=f'class_dense_{i}'\n",
    "        )(class_branch)\n",
    "        class_branch = layers.BatchNormalization(name=f'class_bn_dense_{i}')(class_branch)\n",
    "        class_branch = layers.Activation('relu', name=f'class_activation_{i}')(class_branch)\n",
    "        class_branch = layers.Dropout(config['class_dropout'], name=f'class_dropout_{i}')(class_branch)\n",
    "    \n",
    "    # Classification output: sigmoid for binary classification\n",
    "    classification_output = layers.Dense(\n",
    "        units=1,\n",
    "        activation='sigmoid',\n",
    "        name='classification_output'\n",
    "    )(class_branch)\n",
    "    \n",
    "    # ===== Branch 2: Regression (Outcome Prediction) =====\n",
    "    # Reshape shared features for LSTM: (batch, time, features)\n",
    "    reg_branch = layers.Reshape(\n",
    "        (shared_features.shape[1], -1),\n",
    "        name='reg_reshape_for_lstm'\n",
    "    )(shared_features)\n",
    "    \n",
    "    # Bidirectional LSTM for temporal modeling\n",
    "    reg_branch = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=config['reg_lstm_units'],\n",
    "            return_sequences=False,\n",
    "            dropout=config['reg_lstm_dropout'],\n",
    "            recurrent_dropout=config['reg_lstm_recurrent_dropout'],\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='reg_lstm'\n",
    "        ),\n",
    "        name='reg_bidirectional_lstm'\n",
    "    )(reg_branch)\n",
    "    \n",
    "    # Dense layers for regression\n",
    "    for i, units in enumerate(config['reg_dense_units']):\n",
    "        reg_branch = layers.Dense(\n",
    "            units=units,\n",
    "            kernel_regularizer=l2(config['reg_l2']),\n",
    "            kernel_initializer='he_normal',\n",
    "            name=f'reg_dense_{i}'\n",
    "        )(reg_branch)\n",
    "        reg_branch = layers.BatchNormalization(name=f'reg_bn_dense_{i}')(reg_branch)\n",
    "        reg_branch = layers.Activation('relu', name=f'reg_activation_{i}')(reg_branch)\n",
    "        reg_branch = layers.Dropout(config['reg_dropout'], name=f'reg_dropout_{i}')(reg_branch)\n",
    "    \n",
    "    # Regression output: tanh to constrain to [-1, +1]\n",
    "    regression_output = layers.Dense(\n",
    "        units=1,\n",
    "        activation='tanh',\n",
    "        name='regression_output'\n",
    "    )(reg_branch)\n",
    "    \n",
    "    # ===== Build Model with Dual Outputs =====\n",
    "    model = Model(\n",
    "        inputs=inputs,\n",
    "        outputs=[classification_output, regression_output],\n",
    "        name='DualBranch_MetaLabeling_Model'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_dual_branch_model(input_shape, CONFIG)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be199776",
   "metadata": {},
   "source": [
    "## 6. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701affaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with dual losses and metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['learning_rate']),\n",
    "    loss={\n",
    "        'classification_output': 'binary_crossentropy',\n",
    "        'regression_output': 'mse'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'classification_output': CONFIG['classification_weight'],\n",
    "        'regression_output': CONFIG['regression_weight']\n",
    "    },\n",
    "    metrics={\n",
    "        'classification_output': ['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "        'regression_output': ['mae', 'mse']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"\\nLoss configuration:\")\n",
    "print(f\"  Classification: binary_crossentropy (weight={CONFIG['classification_weight']})\")\n",
    "print(f\"  Regression: MSE (weight={CONFIG['regression_weight']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab92fbf",
   "metadata": {},
   "source": [
    "## 7. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d701621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "checkpoint_path = MODEL_DIR / 'best_model.keras'\n",
    "log_dir = MODEL_DIR / 'logs'\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=CONFIG['patience'],\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "    callbacks.CSVLogger(\n",
    "        MODEL_DIR / 'training_history.csv'\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "for cb in callbacks_list:\n",
    "    print(f\"  - {cb.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016827ba",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857818b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\n",
    "        'classification_output': y_train_class,\n",
    "        'regression_output': y_train_reg\n",
    "    },\n",
    "    validation_data=(\n",
    "        X_val,\n",
    "        {\n",
    "            'classification_output': y_val_class,\n",
    "            'regression_output': y_val_reg\n",
    "        }\n",
    "    ),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    epochs=CONFIG['epochs'],\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a6eec",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Classification loss\n",
    "axes[0, 1].plot(history.history['classification_output_loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_classification_output_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Classification Loss (Binary Crossentropy)')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Regression loss\n",
    "axes[0, 2].plot(history.history['regression_output_loss'], label='Train')\n",
    "axes[0, 2].plot(history.history['val_regression_output_loss'], label='Validation')\n",
    "axes[0, 2].set_title('Regression Loss (MSE)')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Loss')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True)\n",
    "\n",
    "# Classification accuracy\n",
    "axes[1, 0].plot(history.history['classification_output_accuracy'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_classification_output_accuracy'], label='Validation')\n",
    "axes[1, 0].set_title('Classification Accuracy')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Classification AUC\n",
    "axes[1, 1].plot(history.history['classification_output_auc'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_classification_output_auc'], label='Validation')\n",
    "axes[1, 1].set_title('Classification AUC')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('AUC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# Regression MAE\n",
    "axes[1, 2].plot(history.history['regression_output_mae'], label='Train')\n",
    "axes[1, 2].plot(history.history['val_regression_output_mae'], label='Validation')\n",
    "axes[1, 2].set_title('Regression MAE')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "axes[1, 2].set_ylabel('MAE')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training history plot saved to {MODEL_DIR / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e4d1b",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\\n\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_class, y_pred_reg = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Flatten predictions\n",
    "y_pred_class = y_pred_class.flatten()\n",
    "y_pred_reg = y_pred_reg.flatten()\n",
    "\n",
    "# ===== Classification Metrics =====\n",
    "print(\"=\"*60)\n",
    "print(\"CLASSIFICATION METRICS (Entry Confidence)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_class_binary = (y_pred_class > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class_binary)\n",
    "precision = precision_score(y_test_class, y_pred_class_binary)\n",
    "recall = recall_score(y_test_class, y_pred_class_binary)\n",
    "f1 = f1_score(y_test_class, y_pred_class_binary)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test_class, y_pred_class_binary)\n",
    "print(cm)\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class_binary, target_names=['Bad Bet', 'Good Bet']))\n",
    "\n",
    "# ===== Regression Metrics =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REGRESSION METRICS (Outcome Prediction)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "# Direction accuracy (sign agreement)\n",
    "sign_agreement = np.mean(np.sign(y_test_reg) == np.sign(y_pred_reg))\n",
    "print(f\"\\nDirection Accuracy (Sign Agreement): {sign_agreement:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c26b8",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Classification - Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Confusion Matrix (Classification)')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "axes[0, 0].set_xticklabels(['Bad Bet', 'Good Bet'])\n",
    "axes[0, 0].set_yticklabels(['Bad Bet', 'Good Bet'])\n",
    "\n",
    "# 2. Classification - Probability Distribution\n",
    "axes[0, 1].hist(y_pred_class[y_test_class == 0], bins=50, alpha=0.6, label='Bad Bet (Actual)', color='red')\n",
    "axes[0, 1].hist(y_pred_class[y_test_class == 1], bins=50, alpha=0.6, label='Good Bet (Actual)', color='green')\n",
    "axes[0, 1].axvline(0.5, color='black', linestyle='--', label='Decision Threshold')\n",
    "axes[0, 1].set_title('Classification Probability Distribution')\n",
    "axes[0, 1].set_xlabel('Predicted Probability')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Regression - Scatter Plot\n",
    "axes[1, 0].scatter(y_test_reg, y_pred_reg, alpha=0.3, s=10)\n",
    "axes[1, 0].plot([-1, 1], [-1, 1], 'r--', label='Perfect Prediction')\n",
    "axes[1, 0].set_title('Regression: Actual vs Predicted')\n",
    "axes[1, 0].set_xlabel('Actual Heatmap Value')\n",
    "axes[1, 0].set_ylabel('Predicted Heatmap Value')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xlim(-1.1, 1.1)\n",
    "axes[1, 0].set_ylim(-1.1, 1.1)\n",
    "\n",
    "# 4. Regression - Residual Distribution\n",
    "residuals = y_test_reg - y_pred_reg\n",
    "axes[1, 1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(0, color='red', linestyle='--', label='Zero Residual')\n",
    "axes[1, 1].set_title('Regression Residual Distribution')\n",
    "axes[1, 1].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'predictions_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Predictions analysis plot saved to {MODEL_DIR / 'predictions_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dec51",
   "metadata": {},
   "source": [
    "## 12. Meta-Labeling Strategy Analysis\n",
    "\n",
    "Analyze how the dual outputs work together for meta-labeling:\n",
    "- Only take trades where classification confidence is high\n",
    "- Use regression output to size/manage the position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-labeling strategy: only take trades with high classification confidence\n",
    "confidence_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "print(\"Meta-Labeling Strategy Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Conf Threshold':<15} {'Trades Taken':<15} {'Avg Heatmap':<15} {'Win Rate':<15} {'Directional Acc':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for threshold in confidence_thresholds:\n",
    "    # Select trades where classification confidence > threshold\n",
    "    selected_mask = y_pred_class > threshold\n",
    "    \n",
    "    if selected_mask.sum() == 0:\n",
    "        print(f\"{threshold:<15.2f} {'No trades':<15} {'-':<15} {'-':<15} {'-':<15}\")\n",
    "        continue\n",
    "    \n",
    "    # Number of trades taken\n",
    "    n_trades = selected_mask.sum()\n",
    "    pct_trades = n_trades / len(y_test_reg) * 100\n",
    "    \n",
    "    # Average heatmap value (strength of signal)\n",
    "    avg_heatmap = np.abs(y_test_reg[selected_mask]).mean()\n",
    "    \n",
    "    # Win rate (trades where heatmap is correct direction)\n",
    "    win_rate = np.mean(np.abs(y_test_reg[selected_mask]) > CONFIDENCE_THRESHOLD)\n",
    "    \n",
    "    # Directional accuracy\n",
    "    dir_acc = np.mean(np.sign(y_test_reg[selected_mask]) == np.sign(y_pred_reg[selected_mask]))\n",
    "    \n",
    "    print(f\"{threshold:<15.2f} {f'{n_trades} ({pct_trades:.1f}%)':<15} {avg_heatmap:<15.4f} {win_rate:<15.2%} {dir_acc:<15.2%}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cadbf",
   "metadata": {},
   "source": [
    "## 13. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f83995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(MODEL_DIR / 'final_model.keras')\n",
    "print(f\"Model saved to {MODEL_DIR / 'final_model.keras'}\")\n",
    "\n",
    "# Save predictions\n",
    "np.save(MODEL_DIR / 'y_test_class_true.npy', y_test_class)\n",
    "np.save(MODEL_DIR / 'y_test_class_pred.npy', y_pred_class)\n",
    "np.save(MODEL_DIR / 'y_test_reg_true.npy', y_test_reg)\n",
    "np.save(MODEL_DIR / 'y_test_reg_pred.npy', y_pred_reg)\n",
    "print(\"Predictions saved.\")\n",
    "\n",
    "# Save configuration and metrics\n",
    "results = {\n",
    "    'config': CONFIG,\n",
    "    'test_metrics': {\n",
    "        'classification': {\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1_score': float(f1)\n",
    "        },\n",
    "        'regression': {\n",
    "            'mae': float(mae),\n",
    "            'mse': float(mse),\n",
    "            'rmse': float(rmse),\n",
    "            'r2': float(r2),\n",
    "            'direction_accuracy': float(sign_agreement)\n",
    "        }\n",
    "    },\n",
    "    'training_info': {\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'best_val_loss': float(min(history.history['val_loss'])),\n",
    "        'final_train_loss': float(history.history['loss'][-1]),\n",
    "        'final_val_loss': float(history.history['val_loss'][-1])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(MODEL_DIR / 'results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Results saved to {MODEL_DIR / 'results.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 3 Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Next: Phase 4 - Custom Loss Functions (ConsistentPeakBFCE, Focal Loss)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
